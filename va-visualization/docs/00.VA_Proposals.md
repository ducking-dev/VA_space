# V–A Space Proposal: 영어 감정 어휘 병합·임베딩 설계서 (Warriner × NRC VAD)

> 목적: **Warriner(≈14k)와 NRC VAD(≈20k)**를 병합하여 **영어 감정 어휘를 가능한 한 넓게 커버**하고, 이 사전을 기반으로 **Valence–Arousal(V–A)** 2차원 공간에 합리적으로 임베딩·시각화·활용할 수 있는 재현가능 파이프라인을 제안한다.

---

## 0. 범위와 원칙

* **Coverage-First & Evidence-Guided**: 어휘 커버리지를 극대화하되, 각 항목의 근거(출처/스케일/불확실성)를 보존.
* **Reproducible-by-Design**: 데이터·코드·설정의 버전 고정, 결과물 자동 생성.
* **Explainable**: 토큰/구/문장 단위 기여도(가중치)와 불확실성(표준편차·신뢰타원)을 함께 제공.
* **Modular**: 사전 병합→정규화→OOV 보강→조합규칙→문장/문서 집계까지 **원자화된 단계**로 구성.

---

## 1. 데이터 소스와 메타데이터 스키마

### 1.1 원천 리소스

* **Warriner et al. 2013**: 13,915 lemmas, 스케일 1–9, V/A/D **Mean + SD** 제공.
* **NRC VAD 2018**: ~20,000 words, 스케일 0–1, V/A/D **Mean** 제공(BWS 기반).
* (선택) **ANEW**, **NRC Emotion Lexicon(8정서)**, **Geneva Emotion Wheel 라벨셋**: 범주적 정서 라벨 보강용.

### 1.2 통합 스키마 (단어 레벨)

```yaml
schema.version: 1.0
columns:
  - term: str            # 하한: 소문자 lemma, 멀티워드 허용("in love", "not happy")
  - pos: [adj, noun, verb, adv, other, null]
  - source_warriner: bool
  - source_nrc: bool
  - V_mean: float        # 통합 스케일: [-1, 1]
  - A_mean: float        # 통합 스케일: [-1, 1]
  - D_mean: float|null   # dominance, 없으면 null
  - V_sd: float|null     # Warriner에서만
  - A_sd: float|null
  - D_sd: float|null
  - n_raters: int|null   # 가능 시 보강
  - merge_rule: [warriner_only, nrc_only, both_weighted, backoff_embedding, backoff_synonym]
  - quality_flag: [exact, approx, heuristic]
  - license: str         # 각 항목의 사용 조건
  - notes: str|null
```

---

## 2. 정규화·병합 규칙

### 2.1 스케일 정규화

* Warriner: 1–9 → **z-score** 후 목표 범위 **[-1,1]**로 선형 사상.
* NRC: 0–1 → 동일하게 **[-1,1]**로 선형 사상.
* 지배성(D)은 옵션이나 보존 권장.

### 2.2 문자열 정규화·매칭

* 소문자화, 양끝 공백 제거, 하이픈/어포스트로피 정칙화, **lemmatization**(WordNet 기준) 기본.
* **멀티워드**: 원형 유지 + 보조적으로 헤드 단어 파생 키 보관.

### 2.3 충돌 해결(겹치는 단어)

* 공통 항목에 대해 **가중 평균**:

  * 기본: `V* = α·V_warr + (1-α)·V_nrc` (A도 동일)
  * 제안: `α = w(Warriner)` where `w = 1 / (σ² + ε)` (SD가 있는 쪽 가중↑)
  * NRC에는 SD가 없으므로, Warriner SD를 신뢰 가중치로 채택.
* 스케일 불일치 보정: 각 소스의 전역 평균·표준편차를 이용해 **mean-variance alignment** 수행 후 합성.

#### 신뢰도 기반 가중평균 상세 알고리즘

**핵심 원리**: Warriner 데이터의 표준편차(SD) 정보를 신뢰도 지표로 활용하여 동적 가중치를 계산하고, 이를 바탕으로 두 소스의 VAD 값을 지능적으로 병합한다.

**신뢰도 가중치 계산**:
```
신뢰도 가중치 = 1 / (평균_표준편차 + ε)
```
- SD가 낮을수록 → 신뢰도 높음 → 가중치 증가
- SD가 높을수록 → 신뢰도 낮음 → 가중치 감소
- ε = 0.1 (0으로 나누기 방지)

**Pseudo Code**:
```python
def calculate_confidence_weight(valence_sd, arousal_sd, dominance_sd):
    """
    표준편차 기반 신뢰도 가중치 계산
    """
    # 1. 유효한 SD 값들만 수집
    valid_sds = []
    for sd in [valence_sd, arousal_sd, dominance_sd]:
        if sd is not None and sd > 0:
            valid_sds.append(sd)
    
    # 2. SD 정보가 없으면 기본 가중치 반환
    if len(valid_sds) == 0:
        return 1.0
    
    # 3. 평균 SD 계산
    mean_sd = sum(valid_sds) / len(valid_sds)
    
    # 4. 신뢰도 가중치 계산 (SD 역비례)
    confidence_weight = 1.0 / (mean_sd + 0.1)
    
    return confidence_weight

def weighted_merge_vad_values(warriner_data, nrc_data):
    """
    신뢰도 기반 VAD 값 병합
    """
    # 1. Warriner 신뢰도 가중치 계산
    warriner_weight = calculate_confidence_weight(
        warriner_data['valence_sd'],
        warriner_data['arousal_sd'], 
        warriner_data['dominance_sd']
    )
    
    # 2. NRC 가중치 (SD 정보 없으므로 고정값)
    nrc_weight = 1.0
    
    # 3. 총 가중치
    total_weight = warriner_weight + nrc_weight
    
    # 4. VAD 각 차원별 가중 평균
    merged_values = {}
    for dimension in ['valence', 'arousal', 'dominance']:
        warriner_val = warriner_data[dimension]
        nrc_val = nrc_data[dimension]
        
        # 가중 평균 계산
        merged_val = (warriner_weight * warriner_val + nrc_weight * nrc_val) / total_weight
        merged_values[dimension] = merged_val
    
    # 5. 신뢰도 점수 계산
    confidence = min(1.0, warriner_weight / total_weight)
    
    return merged_values, confidence, total_weight

def merge_overlapping_terms(warriner_dict, nrc_dict):
    """
    중복 단어들의 신뢰도 기반 병합
    """
    merged_lexicon = {}
    
    # 모든 고유 키 수집
    all_keys = set(warriner_dict.keys()) | set(nrc_dict.keys())
    
    for term in all_keys:
        warriner_data = warriner_dict.get(term)
        nrc_data = nrc_dict.get(term)
        
        if warriner_data and nrc_data:
            # 두 소스 모두 존재 - 신뢰도 기반 가중 평균
            merged_values, confidence, total_weight = weighted_merge_vad_values(
                warriner_data, nrc_data
            )
            
            merged_lexicon[term] = {
                'valence_mean': merged_values['valence'],
                'arousal_mean': merged_values['arousal'],
                'dominance_mean': merged_values['dominance'],
                'merge_strategy': 'both_weighted',
                'confidence': confidence,
                'total_weight': total_weight,
                'source_warriner': True,
                'source_nrc': True
            }
            
        elif warriner_data:
            # Warriner만 존재
            merged_lexicon[term] = {
                'valence_mean': warriner_data['valence'],
                'arousal_mean': warriner_data['arousal'],
                'dominance_mean': warriner_data['dominance'],
                'merge_strategy': 'warriner_only',
                'confidence': 0.9,  # 높은 신뢰도 (SD 정보 있음)
                'source_warriner': True,
                'source_nrc': False
            }
            
        elif nrc_data:
            # NRC VAD만 존재
            merged_lexicon[term] = {
                'valence_mean': nrc_data['valence'],
                'arousal_mean': nrc_data['arousal'],
                'dominance_mean': nrc_data['dominance'],
                'merge_strategy': 'nrc_only',
                'confidence': 0.7,  # 중간 신뢰도 (SD 정보 없음)
                'source_warriner': False,
                'source_nrc': True
            }
    
    return merged_lexicon
```

**실제 적용 사례**:
```
단어: "anger"
Warriner: V=-0.715, A=0.410, D=-0.068, SD=[1.23, 1.45, 1.67]
NRC VAD:  V=-0.510, A=0.690, D=0.120

신뢰도 가중치 계산:
- 평균 SD = (1.23 + 1.45 + 1.67) / 3 = 1.45
- Warriner 가중치 = 1 / (1.45 + 0.1) = 0.645
- NRC 가중치 = 1.0
- 총 가중치 = 0.645 + 1.0 = 1.645

병합 결과:
- V_merged = (0.645 × -0.715 + 1.0 × -0.510) / 1.645 = -0.592
- A_merged = (0.645 × 0.410 + 1.0 × 0.690) / 1.645 = 0.580
- D_merged = (0.645 × -0.068 + 1.0 × 0.120) / 1.645 = 0.041
- 신뢰도 = 0.645 / 1.645 = 0.392
```

**장점**:
1. **객관적 기준**: 표준편차라는 통계적 지표 활용
2. **동적 가중치**: 각 단어별로 다른 신뢰도 반영
3. **투명성**: 가중치 계산 과정이 명확하고 재현 가능
4. **균형성**: 두 데이터셋의 장점을 모두 활용

### 2.4 비중복 항목(OOV 보강)

* **동의어/형태소 백오프**: 동일 lemma·동의어(WordNet synset) 평균.
* **임베딩 k-NN 백오프**: fastText/GloVe/SBERT 임베딩에서 k=8 이웃의 V–A 가중 평균.
* **형태범주 가중치**: 형용사/감정동사 > 명사 > 기타.
* 품질 플래그 `quality_flag=approx/heuristic`로 표기.

---

## 3. 조합·수정자 규칙(구/문장 레벨)

### 3.1 문장 집계 기본식

주어진 토큰 시퀀스 T에서, 각 토큰 t_i의 (V_i, A_i)와 가중치 w_i에 대해:
[
V_{sent} = \frac{\sum_i w_i · V_i'}{\sum_i w_i}, \quad
A_{sent} = \frac{\sum_i w_i · A_i'}{\sum_i w_i}
]

* 가중치 예시: **TF-IDF × POS boost × attention weight**.

### 3.2 수정자 처리(Shifter Handling)

* **부정(not, no, never)**: `V' = β_neg·V - γ_neg·(V-μ_V)` (예: β=0.6, γ=0.4)
* **강도부사(very, slightly)**: `V' = κ·V`, `A' = κ·A` (very: κ≈1.3, slightly: κ≈0.8)
* **완화어(kind of, maybe)**: A 감소 계수 적용.
* **아이러니/은유**: 문맥 임베딩 기반 신뢰도 하향(불확실성↑).

### 3.3 멀티워드·복합감정 합성

* Plutchik 조합 규칙(예: love=joy+trust)을 **벡터 합성**으로 근사: `x_combo = Σ_i λ_i x_i`,

  * 정규화: 합성 후 L2-정규화 또는 분산 보정.

---

## 4. 2차원 V–A Space 생성·시각화

### 4.1 점과 타원(불확실성) 표현

* 각 term에 대해 점 `p=(V_mean, A_mean)`과 공분산 Σ를 추정.

  * Warriner SD를 활용해 축방향 분산 부여(상관은 0 가정 또는 소규모 검증셋으로 추정).
* 시각화: **신뢰타원(예: 68%/95%)**으로 불확실성 가시화.

### 4.2 영역(Prototype)과 밀도

* **정서 프로토타입**(joy, anger, fear 등) 중심점 μ_c를 설정하고 **가우시안 영역**으로 묘사.
* KDE/각 군집의 분포를 그려 **coverage heatmap**을 출력.

### 4.3 문장/문서 임베딩 흐름도

```mermaid
flowchart LR
  A[Raw text] --> B[Tokenize + Lemmatize]
  B --> C[Lexicon lookup (V,A,D)]
  C --> D[Modifier rules (negation/intensity)]
  D --> E[Weights: TF-IDF × POS × attention]
  E --> F[Sentence V–A aggregate]
  F --> G[Document V–A (temporal/stanza avg)]
  G --> H[Visualization: scatter + KDE + ellipses]
```

---

## 5. 품질관리·평가

### 5.1 정합성(Convergent Validity)

* **교차 소스 상관**: overlap 단어에 대해 (Warriner vs NRC) Pearson/Spearman 상관.
* **외부 벤치**: EmoBank(문장 V–A)와의 상관/MAE.

### 5.2 신뢰성·불확실성

* SD/표준오차 기반 **confidence band** 제공.
* 문장 레벨에선 부정·아이러니 탐지시 **리스크 플래그**.

### 5.3 휴먼 레이팅 소규모 캘리브레이션

* 도메인(리뷰/대화/임상/SNS)별 **200–500 문장 골든셋** 수집, 베이지안 업데이트로 프로토타입 μ_c 재보정.

---

## 6. 구현 계획(모듈·I/O·테스트)

### 6.1 디렉토리·모듈 설계

```bash
va-embed/
├─ data/
│  ├─ raw/                # 원본 CSV/TSV (Warriner, NRC)
│  ├─ interim/            # 정규화·매칭 중간산출물
│  └─ processed/          # merged_vad.csv ([-1,1] 스케일)
├─ src/
│  ├─ ingest/             # 로더: warriner.py, nrc.py
│  ├─ normalize/          # 스케일 정규화, 문자열·lemma 처리
│  ├─ merge/
│  │  ├─ align.py         # mean-variance alignment
│  │  ├─ overlap.py       # 교집합·자카드·상관
│  │  └─ fuse.py          # 가중 결합(α; SD 기반)
│  ├─ backoff/
│  │  ├─ synonyms.py      # WordNet
│  │  └─ knn_embed.py     # fastText/SBERT k-NN 평균
│  ├─ compose/
│  │  ├─ modifiers.py     # 부정/강도/완화 규칙
│  │  └─ aggregate.py     # 문장/문서 집계
│  ├─ viz/
│  │  ├─ plane.py         # scatter + KDE + ellipse
│  │  └─ report.py        # PDF/PNG/HTML 리포트
│  └─ eval/
│     ├─ emobank.py       # 외부 벤치 상관/MAE
│     └─ qa.py            # 무작위 샘플 수동검증 지원
├─ configs/
│  ├─ merge.yaml          # 가중치 α, 백오프 k, POS boost 등
│  ├─ viz.yaml            # 축 범위, 색상, 타원 신뢰수준
│  └─ eval.yaml           # 벤치마크 경로·지표
└─ tests/
   └─ test_merge.py       # 단위테스트
```

### 6.2 핵심 알고리즘 의사코드

```python
# 1) 로드 & 정규화
W = load_warriner().scale_to([-1,1])  # keep SD
N = load_nrc().scale_to([-1,1])       # mean only

# 2) 매칭 키 생성
W.key = normalize_str(lemmatize(W.word))
N.key = normalize_str(lemmatize(N.word))

# 3) 합치기
M = outer_join_on_key(W, N)
for row in M:
    if row.has_both:
        alpha = weight_from_sd(row.V_sd_warr, row.A_sd_warr)
        row.V_mean = alpha*row.V_warr + (1-alpha)*row.V_nrc
        row.A_mean = alpha*row.A_warr + (1-alpha)*row.A_nrc
        row.merge_rule = 'both_weighted'
    elif row.from_W:
        row.V_mean, row.A_mean = row.V_warr, row.A_warr
        row.merge_rule = 'warriner_only'
    else:
        row.V_mean, row.A_mean = row.V_nrc, row.A_nrc
        row.merge_rule = 'nrc_only'

# 4) OOV 백오프
for term in missing_terms:
    cand = synonyms(term) + knn_neighbors(term)
    row.V_mean, row.A_mean = weighted_avg(cand)
    row.merge_rule = 'backoff'

# 5) 내보내기
save_csv(M, 'processed/merged_vad.csv')
```

### 6.3 검증·리포팅 자동화

* `make report`: 자카드/상관/분포, 샘플 시각화, 에러로그 요약, 라이선스 표 자동 생성.
* `make demo`: 입력 텍스트 → V–A 위치/타원 플롯(HTML) 생성.

---

## 7. 라이선스·윤리·거버넌스

* 각 리소스의 **라이선스/인용** 명시(파일 단위로 provenance 메타데이터 포함).
* **버전 잠금**: 해시와 릴리즈 태그 기록.
* **Bias 체크**: 빈도/도메인별 편향, 성·인종 관련 민감어 분석(필터/경고 레이어).
* **안전장치**: 의료·임상 등 고위험 영역 사용시 경고 및 성능 한계 공지.

---

## 8. 산출물(Deliverables) & DoD

* `processed/merged_vad.csv` (≈25k+ 유니크 항목)
* `docs/va_space_guide.md` (임베딩·가중치·수정자 규칙 설명)
* `reports/merge_quality.html` (자카드·상관·KDE·타원 도표)
* `demo/va_viewer.html` (검색/하이라이트 가능한 V–A 인터랙티브 뷰어)
* **Definition of Done (DoD)**

  1. 중복 키 0건, NaN/±∞ 0건
  2. overlap 상관 r≥0.7 (valence 기준) 달성
  3. EmoBank 검증 MAE, 기존 baseline 대비 개선
  4. 문장 데모에서 부정/강도 규칙 검증 사례 통과(테스트 케이스 제공)

---

## 9. 로드맵(2주 스프린트)

| 주/일    | 작업                | 산출물                                     |
| ------ | ----------------- | --------------------------------------- |
| W1D1–2 | 원천 데이터 수집·스키마 설계  | `data/raw/*`, `schema v1.0`             |
| W1D3–4 | 정규화·스케일 정렬·키 매칭   | `interim/*` 중간 파일                       |
| W1D5   | 충돌/가중 결합·OOV 백오프  | `processed/merged_vad.csv` v0           |
| W2D1   | 수정자 규칙·문장 집계 구현   | `src/compose/*`                         |
| W2D2   | 시각화·리포트 자동화       | `reports/*.html`, `viz/*.png`           |
| W2D3   | 외부 벤치(EmoBank) 평가 | `reports/metrics.json`                  |
| W2D4–5 | 휴먼 캘리브·최종 보정      | `processed/merged_vad.csv` v1, `docs/*` |

---

## 10. 부록 A — 프로토타입 좌표(초기 시드)

> 실제 적용 코퍼스에서 소규모 라벨로 **베이지안 업데이트** 권장.

| Emotion       |     V |     A |
| ------------- | ----: | ----: |
| joy           | +0.80 | +0.55 |
| serenity      | +0.60 | -0.20 |
| pride         | +0.55 | +0.30 |
| gratitude     | +0.55 | +0.10 |
| love          | +0.70 | +0.35 |
| amusement     | +0.65 | +0.45 |
| awe           | +0.20 | +0.70 |
| surprise      |  0.00 | +0.70 |
| anticipation  | +0.10 | +0.40 |
| interest      | +0.30 | +0.25 |
| calm          | +0.40 | -0.40 |
| sadness       | -0.70 | -0.30 |
| grief         | -0.85 | -0.20 |
| anger         | -0.70 | +0.70 |
| disgust       | -0.65 | +0.35 |
| contempt      | -0.60 | +0.20 |
| fear          | -0.75 | +0.75 |
| anxiety       | -0.55 | +0.60 |
| shame         | -0.70 | +0.15 |
| guilt         | -0.60 | +0.10 |
| embarrassment | -0.40 | +0.30 |
| frustration   | -0.55 | +0.55 |
| boredom       | -0.30 | -0.60 |
| loneliness    | -0.55 | -0.25 |
| relief        | +0.45 | -0.30 |
| hope          | +0.50 | +0.15 |

---

## 11. 부록 B — 설정 예시(configs/merge.yaml)

```yaml
scale:
  target: [-1, 1]
  method: linear

weights:
  alpha_from_sd:
    min_sd: 0.2     # SD 작을수록 Warriner 가중↑
    max_sd: 1.5
    clip: [0.2, 0.8]

backoff:
  synonyms: true
  knn:
    model: fasttext.cc.en
    k: 8
    min_cos: 0.35
  pos_boost:
    adj: 1.3
    verb: 1.2
    noun: 1.0
    adv: 1.1

modifiers:
  negation: {beta: 0.6, gamma: 0.4}
  intensifiers: {very: 1.3, extremely: 1.5, slightly: 0.8}
  hedges: {maybe: 0.85, kinda: 0.85}

viz:
  ellipse_conf: 0.68
  plane_limits: {V: [-1,1], A: [-1,1]}
```

---

## 12. 마무리

본 설계서는 **사전 기반의 투명성**과 **임베딩 기반의 일반화**를 결합해, 영어 감정 어휘의 **넓은 커버리지**와 **합리적 V–A 좌표화**를 동시에 달성하도록 고안되었다. 이후 단계로는 (1) 도메인별 캘리브레이션, (2) 다국어 확장(번역-투영/교차언어 정렬), (3) 멀티모달(음성·영상) 융합이 자연스럽게 연결된다.
